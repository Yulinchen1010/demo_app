from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response
from pydantic import BaseModel, Field
from typing import Optional, List
import sqlite3
import pandas as pd
import numpy as np
import os
import joblib
from datetime import datetime, timedelta, timezone
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import io
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib import font_manager
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šä¸­æ–‡å­—é«”
def setup_chinese_font():
    """è¨­å®š matplotlib ä¸­æ–‡å­—é«”"""
    try:
        # å˜—è©¦ä½¿ç”¨ç³»çµ±ä¸­æ–‡å­—é«”
        fonts = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'STHeiti', 'PingFang TC', 'Noto Sans CJK TC']
        for font in fonts:
            if any(font.lower() in f.name.lower() for f in font_manager.fontManager.ttflist):
                plt.rcParams['font.sans-serif'] = [font]
                plt.rcParams['axes.unicode_minus'] = False
                print(f"âœ… ä½¿ç”¨å­—é«”: {font}")
                return
        # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ DejaVu Sansï¼ˆé¡¯ç¤ºè‹±æ–‡ï¼‰
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—é«”ï¼Œä½¿ç”¨è‹±æ–‡é¡¯ç¤º")
    except:
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        print("âš ï¸ å­—é«”è¨­å®šå¤±æ•—ï¼Œä½¿ç”¨é è¨­å­—é«”")

setup_chinese_font()

# ==================== åˆå§‹è¨­å®š ====================
DB_PATH = "fatigue_data.db"
MODEL_PATH = "models/fatigue_regressor.pkl"
os.makedirs("models", exist_ok=True)

# è¨­å®šæ™‚å€ï¼šå°ç£æ™‚é–“ (UTC+8)
TZ_TAIWAN = timezone(timedelta(hours=8))

def get_taiwan_time():
    """å–å¾—å°ç£ç•¶å‰æ™‚é–“"""
    return datetime.now(TZ_TAIWAN)

app = FastAPI(title="ç–²å‹é æ¸¬ç³»çµ±", version="4.0")

# CORS è¨­å®šï¼ˆå…è¨± APP é€£æ¥ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== è³‡æ–™æ¨¡å‹ ====================
class SensorData(BaseModel):
    worker_id: str
    percent_mvc: float = Field(ge=0, le=100)
    timestamp: Optional[str] = None

class BatchUpload(BaseModel):
    data: List[SensorData]

# ==================== è³‡æ–™åº«åˆå§‹åŒ– ====================
def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("""
        CREATE TABLE IF NOT EXISTS sensor_data (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            worker_id TEXT NOT NULL,
            timestamp TEXT NOT NULL,
            percent_mvc REAL NOT NULL
        )
    """)
    c.execute("CREATE INDEX IF NOT EXISTS idx_worker_timestamp ON sensor_data(worker_id, timestamp)")
    conn.commit()
    conn.close()

init_db()

# ==================== è¼‰å…¥/è¨“ç·´æ¨¡å‹ ====================
def load_or_train_model():
    if os.path.exists(MODEL_PATH):
        print("âœ… è¼‰å…¥å·²è¨“ç·´æ¨¡å‹")
        return joblib.load(MODEL_PATH)
    
    print("ğŸ”§ è¨“ç·´æ–°æ¨¡å‹...")
    n = 3000
    rng = np.random.RandomState(42)
    percent_mvc = rng.uniform(0, 100, size=n)
    mvc_change = rng.uniform(-20, 30, size=n)  # MVCè®ŠåŒ–é‡
    time_elapsed = rng.uniform(0, 240, size=n)  # ç¶“éæ™‚é–“(åˆ†é˜)
    
    X = np.vstack([percent_mvc, mvc_change, time_elapsed]).T
    # é¢¨éšªåˆ†æ•¸: MVCå¢åŠ è¶Šå¤šï¼Œé¢¨éšªè¶Šé«˜
    y = mvc_change * 2 + time_elapsed * 0.1 + rng.normal(0, 5, n)
    y = np.clip(y, -20, 100)
    
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestRegressor(n_estimators=50, random_state=42)
    model.fit(X_train, y_train)
    
    joblib.dump(model, MODEL_PATH)
    print("âœ… æ¨¡å‹è¨“ç·´å®Œæˆ")
    return model

# åˆå§‹åŒ–æ¨¡å‹
MODEL = load_or_train_model()

# ==================== è¼”åŠ©å‡½æ•¸ ====================
def get_worker_data(worker_id: str) -> pd.DataFrame:
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query(
        "SELECT * FROM sensor_data WHERE worker_id = ? ORDER BY timestamp DESC LIMIT 1000",
        conn, params=(worker_id,)
    )
    conn.close()
    if not df.empty:
        df['timestamp'] = pd.to_datetime(df['timestamp'])
    return df

def calculate_risk_level(mvc_change: float) -> tuple:
    """æ ¹æ“šMVCè®ŠåŒ–é‡è¨ˆç®—é¢¨éšªç­‰ç´š"""
    if mvc_change >= 30:
        return "é«˜åº¦", 3, "#e74c3c"
    elif mvc_change >= 15:
        return "ä¸­åº¦", 2, "#f39c12"
    else:
        return "ä½åº¦", 1, "#27ae60"

def predict_fatigue_risk(current_mvc: float, initial_mvc: float, time_elapsed: float) -> float:
    """é æ¸¬æœªä¾†çš„MVCè®ŠåŒ–(é¢¨éšªåˆ†æ•¸)"""
    mvc_change = current_mvc - initial_mvc
    X = np.array([[current_mvc, mvc_change, time_elapsed]])
    return float(MODEL.predict(X)[0])

# ==================== API ç«¯é» ====================

@app.get("/")
def home():
    return {
        "service": "ç–²å‹é æ¸¬ç³»çµ±",
        "version": "4.0",
        "description": "åŸºæ–¼ MVC ç™¾åˆ†æ¯”çš„ç–²å‹é¢¨éšªç›£æ¸¬",
        "endpoints": {
            "ä¸Šå‚³å–®ç­†": "POST /upload",
            "æ‰¹æ¬¡ä¸Šå‚³": "POST /upload_batch",
            "å³æ™‚ç‹€æ…‹": "GET /status/{worker_id}",
            "é æ¸¬æ•¸æ“š": "GET /predict/{worker_id}",
            "é æ¸¬åœ–è¡¨": "GET /chart/{worker_id}",
            "æ‰€æœ‰å·¥ä½œè€…": "GET /workers",
            "ç”Ÿæˆæ¸¬è©¦": "POST /test/generate/{worker_id}?count=10",
            "æ¸…ç©ºè³‡æ–™": "DELETE /clear/{worker_id}",
            "ç³»çµ±å¥åº·": "GET /health",
            "APIæ–‡ä»¶": "GET /docs"
        }
    }

@app.post('/upload')
def upload(item: SensorData):
    """ä¸Šå‚³å–®ç­†æ„Ÿæ¸¬å™¨è³‡æ–™ (ç”± APP è‡ªå‹•ä¸Šå‚³)"""
    ts = item.timestamp or datetime.utcnow().isoformat()
    
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute(
        "INSERT INTO sensor_data (worker_id, timestamp, percent_mvc) VALUES (?, ?, ?)",
        (item.worker_id, ts, item.percent_mvc)
    )
    conn.commit()
    conn.close()
    
    print(f"âœ… ä¸Šå‚³æˆåŠŸ: {item.worker_id} | MVC={item.percent_mvc}% | æ™‚é–“={ts}")
    
    return {
        "status": "success",
        "worker_id": item.worker_id,
        "timestamp": ts,
        "mvc": item.percent_mvc
    }

@app.post('/upload_batch')
def upload_batch(batch: BatchUpload):
    """æ‰¹æ¬¡ä¸Šå‚³å¤šç­†è³‡æ–™"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    for item in batch.data:
        ts = item.timestamp or datetime.utcnow().isoformat()
        c.execute(
            "INSERT INTO sensor_data (worker_id, timestamp, percent_mvc) VALUES (?, ?, ?)",
            (item.worker_id, ts, item.percent_mvc)
        )
    
    conn.commit()
    conn.close()
    
    print(f"âœ… æ‰¹æ¬¡ä¸Šå‚³æˆåŠŸ: {len(batch.data)} ç­†")
    
    return {
        "status": "success",
        "uploaded": len(batch.data)
    }

@app.get('/status/{worker_id}')
def get_status(worker_id: str):
    """å–å¾—å·¥ä½œè€…å³æ™‚ç‹€æ…‹"""
    df = get_worker_data(worker_id)
    if df.empty:
        raise HTTPException(404, f"æ‰¾ä¸åˆ° {worker_id} çš„è³‡æ–™")
    
    # æœ€æ–°æ•¸æ“š
    latest = df.iloc[0]
    current_mvc = float(latest['percent_mvc'])
    
    # åˆå§‹æ•¸æ“š (ç¬¬ä¸€ç­†è³‡æ–™)
    initial = df.iloc[-1]
    initial_mvc = float(initial['percent_mvc'])
    
    # è¨ˆç®—MVCè®ŠåŒ–é‡
    mvc_change = current_mvc - initial_mvc
    
    # è¨ˆç®—ç¶“éæ™‚é–“(åˆ†é˜)
    time_diff = (latest['timestamp'] - initial['timestamp']).total_seconds() / 60
    
    # é¢¨éšªç­‰ç´šè©•ä¼°
    risk_label, risk_level, risk_color = calculate_risk_level(mvc_change)
    
    # è¨ˆç®—å¹³å‡MVC (æœ€è¿‘10ç­†)
    recent_avg = df.head(10)['percent_mvc'].mean()
    
    return {
        "worker_id": worker_id,
        "current_mvc": round(current_mvc, 2),
        "initial_mvc": round(initial_mvc, 2),
        "mvc_change": round(mvc_change, 2),
        "mvc_change_rate": round(mvc_change / time_diff if time_diff > 0 else 0, 3),
        "fatigue_risk": risk_label,
        "risk_level": risk_level,
        "risk_color": risk_color,
        "time_elapsed_minutes": round(time_diff, 1),
        "recent_avg_mvc": round(recent_avg, 2),
        "last_update": str(latest['timestamp']),
        "data_count": len(df),
        "recommendation": get_recommendation(risk_level, mvc_change)
    }

def get_recommendation(risk_level: int, mvc_change: float) -> str:
    """æ ¹æ“šé¢¨éšªç­‰ç´šæä¾›å»ºè­°"""
    if risk_level == 3:
        return "âš ï¸ é«˜é¢¨éšªï¼å»ºè­°ç«‹å³ä¼‘æ¯ 15-20 åˆ†é˜"
    elif risk_level == 2:
        return "âš¡ ä¸­åº¦é¢¨éšªï¼Œå»ºè­°èª¿æ•´å·¥ä½œå§¿å‹¢æˆ–çŸ­æš«ä¼‘æ¯"
    else:
        return "âœ… ç‹€æ…‹è‰¯å¥½ï¼Œç¹¼çºŒä¿æŒ"

@app.get('/predict/{worker_id}')
def predict(worker_id: str, horizon: int = 120):
    """å–å¾—æœªä¾†MVCè®ŠåŒ–é æ¸¬ (JSON)"""
    df = get_worker_data(worker_id)
    if df.empty:
        raise HTTPException(404, f"æ‰¾ä¸åˆ° {worker_id} çš„è³‡æ–™")
    
    latest = df.iloc[0]
    initial = df.iloc[-1]
    
    current_mvc = float(latest['percent_mvc'])
    initial_mvc = float(initial['percent_mvc'])
    current_time = (latest['timestamp'] - initial['timestamp']).total_seconds() / 60
    
    # ç”Ÿæˆæœªä¾†é æ¸¬
    predictions = []
    for t in range(0, min(horizon, 240) + 1, 10):
        future_time = current_time + t
        predicted_risk = predict_fatigue_risk(current_mvc, initial_mvc, future_time)
        predicted_mvc = initial_mvc + predicted_risk
        
        risk_label, risk_level, _ = calculate_risk_level(predicted_risk)
        
        predictions.append({
            "minutes_from_now": t,
            "predicted_mvc": round(predicted_mvc, 2),
            "mvc_change": round(predicted_risk, 2),
            "risk_level": risk_label
        })
    
    return {
        "worker_id": worker_id,
        "current_state": {
            "mvc": current_mvc,
            "initial_mvc": initial_mvc,
            "current_change": round(current_mvc - initial_mvc, 2)
        },
        "predictions": predictions
    }

@app.get('/chart/{worker_id}')
def chart(worker_id: str, horizon: int = 120):
    """å–å¾—MVCè®ŠåŒ–é æ¸¬æ›²ç·šåœ–"""
    df = get_worker_data(worker_id)
    if df.empty:
        raise HTTPException(404, f"æ‰¾ä¸åˆ° {worker_id} çš„è³‡æ–™")
    
    latest = df.iloc[0]
    initial = df.iloc[-1]
    
    current_mvc = float(latest['percent_mvc'])
    initial_mvc = float(initial['percent_mvc'])
    current_time = (latest['timestamp'] - initial['timestamp']).total_seconds() / 60
    
    # ç”Ÿæˆé æ¸¬
    times = np.arange(0, min(horizon, 240) + 1, 5)
    mvc_values = []
    
    for t in times:
        future_time = current_time + t
        predicted_risk = predict_fatigue_risk(current_mvc, initial_mvc, future_time)
        predicted_mvc = initial_mvc + predicted_risk
        mvc_values.append(predicted_mvc)
    
    # ç¹ªåœ–
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # åœ–1: MVCçµ•å°å€¼é æ¸¬
    ax1.plot(times, mvc_values, 'o-', color='#667eea', linewidth=2.5, markersize=5)
    ax1.axhline(initial_mvc, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='åˆå§‹ MVC')
    ax1.axhline(current_mvc, color='blue', linestyle='--', linewidth=1.5, alpha=0.7, label='ç•¶å‰ MVC')
    ax1.fill_between(times, initial_mvc + 10, initial_mvc + 20, alpha=0.2, color='orange', label='ä¸­åº¦é¢¨éšªå€')
    ax1.fill_between(times, initial_mvc + 20, 100, alpha=0.2, color='red', label='é«˜åº¦é¢¨éšªå€')
    ax1.set_xlabel('æœªä¾†åˆ†é˜æ•¸', fontsize=12, fontweight='bold')
    ax1.set_ylabel('é æ¸¬ MVC (%)', fontsize=12, fontweight='bold')
    ax1.set_title(f'MVC ç™¾åˆ†æ¯”é æ¸¬ - {worker_id}', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    ax1.legend(loc='best')
    ax1.set_ylim([0, 100])
    
    # åœ–2: MVCè®ŠåŒ–é‡
    mvc_changes = np.array(mvc_values) - initial_mvc
    ax2.plot(times, mvc_changes, 'o-', color='#f5576c', linewidth=2.5, markersize=5)
    ax2.axhline(0, color='gray', linestyle='-', linewidth=1, alpha=0.5)
    ax2.axhline(10, color='orange', linestyle='--', linewidth=1.5, alpha=0.7, label='ä¸­åº¦é¢¨éšª (+10%)')
    ax2.axhline(20, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='é«˜åº¦é¢¨éšª (+20%)')
    ax2.fill_between(times, 10, 20, alpha=0.2, color='orange')
    ax2.fill_between(times, 20, 100, alpha=0.2, color='red')
    ax2.set_xlabel('æœªä¾†åˆ†é˜æ•¸', fontsize=12, fontweight='bold')
    ax2.set_ylabel('MVC è®ŠåŒ–é‡ (%)', fontsize=12, fontweight='bold')
    ax2.set_title(f'MVC è®ŠåŒ–é‡é æ¸¬ - {worker_id}', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='best')
    
    buf = io.BytesIO()
    plt.tight_layout()
    plt.savefig(buf, format='png', dpi=120)
    plt.close()
    buf.seek(0)
    
    return Response(content=buf.getvalue(), media_type='image/png')

@app.get('/workers')
def list_workers():
    """åˆ—å‡ºæ‰€æœ‰å·¥ä½œè€…"""
    conn = sqlite3.connect(DB_PATH)
    df = pd.read_sql_query(
        """SELECT worker_id, COUNT(*) as count, 
           MAX(timestamp) as last_update,
           AVG(percent_mvc) as avg_mvc,
           MIN(percent_mvc) as min_mvc,
           MAX(percent_mvc) as max_mvc
           FROM sensor_data 
           GROUP BY worker_id""",
        conn
    )
    conn.close()
    
    # è¨ˆç®—æ¯å€‹å·¥ä½œè€…çš„é¢¨éšªç‹€æ…‹
    workers = []
    for _, row in df.iterrows():
        mvc_range = row['max_mvc'] - row['min_mvc']
        risk_label, risk_level, risk_color = calculate_risk_level(mvc_range)
        
        workers.append({
            "worker_id": row['worker_id'],
            "count": int(row['count']),
            "last_update": row['last_update'],
            "avg_mvc": round(row['avg_mvc'], 2),
            "min_mvc": round(row['min_mvc'], 2),
            "max_mvc": round(row['max_mvc'], 2),
            "mvc_range": round(mvc_range, 2),
            "risk_level": risk_label,
            "risk_color": risk_color
        })
    
    return {"workers": workers, "total": len(workers)}

@app.delete('/clear/{worker_id}')
def clear(worker_id: str):
    """æ¸…ç©ºå·¥ä½œè€…è³‡æ–™"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("DELETE FROM sensor_data WHERE worker_id = ?", (worker_id,))
    deleted = c.rowcount
    conn.commit()
    conn.close()
    
    print(f"ğŸ—‘ï¸ å·²åˆªé™¤ {worker_id} çš„ {deleted} ç­†è³‡æ–™")
    
    return {
        "status": "success",
        "worker_id": worker_id,
        "deleted": deleted,
        "message": f"å·²æˆåŠŸåˆªé™¤ {worker_id} çš„æ‰€æœ‰è¨˜éŒ„"
    }

@app.delete('/clear_all')
def clear_all():
    """æ¸…ç©ºæ‰€æœ‰è³‡æ–™ï¼ˆæ…ç”¨ï¼‰"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM sensor_data")
    total = c.fetchone()[0]
    c.execute("DELETE FROM sensor_data")
    conn.commit()
    conn.close()
    
    print(f"ğŸ—‘ï¸ å·²æ¸…ç©ºè³‡æ–™åº«ï¼Œåˆªé™¤ {total} ç­†è³‡æ–™")
    
    return {
        "status": "success",
        "deleted": total,
        "message": f"å·²æ¸…ç©ºæ‰€æœ‰è³‡æ–™ï¼Œå…±åˆªé™¤ {total} ç­†è¨˜éŒ„"
    }

@app.post('/test/generate/{worker_id}')
def generate_test(worker_id: str, count: int = 20):
    """ç”Ÿæˆæ¸¬è©¦è³‡æ–™ (æ¨¡æ“¬æ¯åˆ†é˜ä¸Šå‚³)"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    # å¾30%é–‹å§‹ï¼Œéš¨æ©Ÿéå¢æ¨¡æ“¬ç–²å‹ç´¯ç©
    base_mvc = 30.0
    
    for i in range(count):
        ts = (datetime.utcnow() - timedelta(minutes=count-i)).isoformat()
        # MVCéš¨æ™‚é–“å¢åŠ ï¼Œæ¨¡æ“¬ç–²å‹ç´¯ç©
        mvc = base_mvc + i * np.random.uniform(0.5, 2.0) + np.random.normal(0, 2)
        mvc = np.clip(mvc, 0, 100)
        
        c.execute(
            "INSERT INTO sensor_data (worker_id, timestamp, percent_mvc) VALUES (?, ?, ?)",
            (worker_id, ts, float(mvc))
        )
    
    conn.commit()
    conn.close()
    
    print(f"âœ… å·²ç”Ÿæˆ {count} ç­†æ¸¬è©¦è³‡æ–™ (æ¨¡æ“¬æ¯åˆ†é˜ä¸Šå‚³)")
    
    return {
        "status": "success",
        "worker_id": worker_id,
        "generated": count,
        "message": f"å·²ç”Ÿæˆ {count} ç­†æ¸¬è©¦è³‡æ–™ï¼Œæ¨¡æ“¬ {count} åˆ†é˜çš„å·¥ä½œè¨˜éŒ„"
    }

@app.get('/health')
def health():
    """ç³»çµ±å¥åº·æª¢æŸ¥"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM sensor_data")
    total = c.fetchone()[0]
    c.execute("SELECT COUNT(DISTINCT worker_id) FROM sensor_data")
    workers = c.fetchone()[0]
    conn.close()
    
    return {
        "status": "healthy",
        "model_loaded": MODEL is not None,
        "total_records": total,
        "total_workers": workers,
        "database": DB_PATH,
        "version": "4.0"
    }

if __name__ == '__main__':
    print("ğŸš€ ç–²å‹é æ¸¬ç³»çµ±å·²å•Ÿå‹• (v4.0)")
    print("ğŸ“ æœ¬æ©Ÿ: http://localhost:8000")
    print("ğŸ“ æ–‡ä»¶: http://localhost:8000/docs")
    print("ğŸ’¡ ç³»çµ±ç‰¹é»: åŸºæ–¼ MVC è®ŠåŒ–é‡çš„ç–²å‹é¢¨éšªè©•ä¼°")
    print("â±ï¸  å»ºè­° APP æ¯åˆ†é˜è‡ªå‹•ä¸Šå‚³ MVC æ•¸æ“š")
    print("\nå•Ÿå‹•å‘½ä»¤: uvicorn main:app --reload --host 0.0.0.0 --port 8000")